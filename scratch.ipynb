{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import math\n",
    "from typing import Tuple\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n",
      "(12013, 75)\n",
      "(1671706, 4)\n",
      "(12013, 3)\n"
     ]
    }
   ],
   "source": [
    "patients = pd.read_csv(\"data/patients.csv\").fillna(0)\n",
    "encounters = pd.read_csv(\"data/admissions.csv\").iloc[:, 1:].fillna(0)\n",
    "lab_events = pd.read_csv(\"data/lab_events.csv\").iloc[:, [0, 1, 2, 3]].fillna(0)\n",
    "labels = pd.read_csv(\"data/labels.csv\").fillna(0)\n",
    "print(patients.shape)\n",
    "print(encounters.shape)\n",
    "print(lab_events.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admission_type_AMBULATORY OBSERVATION</th>\n",
       "      <th>admission_type_DIRECT EMER.</th>\n",
       "      <th>admission_type_DIRECT OBSERVATION</th>\n",
       "      <th>admission_type_ELECTIVE</th>\n",
       "      <th>admission_type_EU OBSERVATION</th>\n",
       "      <th>admission_type_EW EMER.</th>\n",
       "      <th>admission_type_OBSERVATION ADMIT</th>\n",
       "      <th>admission_type_SURGICAL SAME DAY ADMISSION</th>\n",
       "      <th>...</th>\n",
       "      <th>race_PATIENT DECLINED TO ANSWER</th>\n",
       "      <th>race_PORTUGUESE</th>\n",
       "      <th>race_SOUTH AMERICAN</th>\n",
       "      <th>race_UNABLE TO OBTAIN</th>\n",
       "      <th>race_UNKNOWN</th>\n",
       "      <th>race_WHITE</th>\n",
       "      <th>race_WHITE - BRAZILIAN</th>\n",
       "      <th>race_WHITE - EASTERN EUROPEAN</th>\n",
       "      <th>race_WHITE - OTHER EUROPEAN</th>\n",
       "      <th>race_WHITE - RUSSIAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001843</td>\n",
       "      <td>21728396</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002751</td>\n",
       "      <td>22002850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004764</td>\n",
       "      <td>24817563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10012688</td>\n",
       "      <td>23145708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10013300</td>\n",
       "      <td>23698883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  admission_type_AMBULATORY OBSERVATION  \\\n",
       "0    10001843  21728396                                      0   \n",
       "1    10002751  22002850                                      0   \n",
       "2    10004764  24817563                                      0   \n",
       "3    10012688  23145708                                      0   \n",
       "4    10013300  23698883                                      0   \n",
       "\n",
       "   admission_type_DIRECT EMER.  admission_type_DIRECT OBSERVATION  \\\n",
       "0                            0                                  0   \n",
       "1                            0                                  0   \n",
       "2                            0                                  0   \n",
       "3                            0                                  0   \n",
       "4                            0                                  0   \n",
       "\n",
       "   admission_type_ELECTIVE  admission_type_EU OBSERVATION  \\\n",
       "0                        0                              0   \n",
       "1                        0                              0   \n",
       "2                        0                              0   \n",
       "3                        0                              0   \n",
       "4                        0                              0   \n",
       "\n",
       "   admission_type_EW EMER.  admission_type_OBSERVATION ADMIT  \\\n",
       "0                        0                                 1   \n",
       "1                        1                                 0   \n",
       "2                        0                                 0   \n",
       "3                        1                                 0   \n",
       "4                        1                                 0   \n",
       "\n",
       "   admission_type_SURGICAL SAME DAY ADMISSION  ...  \\\n",
       "0                                           0  ...   \n",
       "1                                           0  ...   \n",
       "2                                           0  ...   \n",
       "3                                           0  ...   \n",
       "4                                           0  ...   \n",
       "\n",
       "   race_PATIENT DECLINED TO ANSWER  race_PORTUGUESE  race_SOUTH AMERICAN  \\\n",
       "0                                0                0                    0   \n",
       "1                                0                0                    0   \n",
       "2                                0                0                    0   \n",
       "3                                0                0                    0   \n",
       "4                                0                0                    0   \n",
       "\n",
       "   race_UNABLE TO OBTAIN  race_UNKNOWN  race_WHITE  race_WHITE - BRAZILIAN  \\\n",
       "0                      0             0           1                       0   \n",
       "1                      0             0           1                       0   \n",
       "2                      0             0           1                       0   \n",
       "3                      0             0           1                       0   \n",
       "4                      0             0           1                       0   \n",
       "\n",
       "   race_WHITE - EASTERN EUROPEAN  race_WHITE - OTHER EUROPEAN  \\\n",
       "0                              0                            0   \n",
       "1                              0                            0   \n",
       "2                              0                            0   \n",
       "3                              0                            0   \n",
       "4                              0                            0   \n",
       "\n",
       "   race_WHITE - RUSSIAN  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encounters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "722\n"
     ]
    }
   ],
   "source": [
    "num_lab_types = len(lab_events[\"itemid\"].unique())\n",
    "print(num_lab_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientEncounter(Dataset):\n",
    "    '''\n",
    "    PatientEncounter Dataset class\n",
    "    '''\n",
    "    def __init__(self, patients, encounters, lab_events, labels):\n",
    "        super().__init__()\n",
    "        self.patients = patients\n",
    "        self.encounters = encounters\n",
    "        self.lab_events = lab_events\n",
    "        self.labels = labels\n",
    "        self.patient_ids = encounters.subject_id\n",
    "        self.encounter_ids = encounters.hadm_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        patient_id = self.patient_ids[index]\n",
    "        encounter_id = self.encounter_ids[index]\n",
    "        \n",
    "        # Load data for the given patient-encounter\n",
    "        data_patient = torch.from_numpy(self.patients.loc[self.patients.subject_id == patient_id].iloc[:, 1:].astype(float).values).to(device)\n",
    "        data_encounter = torch.from_numpy(self.encounters.loc[(self.encounters.subject_id == patient_id) & (self.encounters.hadm_id == encounter_id)].iloc[:, 2:].astype(float).values).to(device)\n",
    "        data_lab_events = torch.from_numpy(self.lab_events.loc[(self.lab_events.subject_id == patient_id) & (self.lab_events.hadm_id == encounter_id)].iloc[:, 2:].astype(float).values).to(device)\n",
    "        X = [data_patient, data_encounter, data_lab_events]\n",
    "        y = torch.from_numpy(self.labels.loc[(self.labels.subject_id == patient_id) & (self.labels.hadm_id == encounter_id)].READMIT_ONE_WEEK.values).to(device)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "class Patient(Dataset):\n",
    "    '''\n",
    "    Patient Dataset class\n",
    "    '''\n",
    "    def __init__(self, patients, labels):\n",
    "        super().__init__()\n",
    "        self.patients = patients\n",
    "        self.labels = labels\n",
    "        self.patient_ids = patients.subject_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        patient_id = self.patient_ids[index]\n",
    "        \n",
    "        # Load data for the given patient\n",
    "        data_patient = torch.from_numpy(self.patients.loc[self.patients.subject_id == patient_id].values).to(device)\n",
    "        X = [data_patient]\n",
    "        y = torch.from_numpy(self.labels.loc[self.labels.subject_id == patient_id].READMIT_ONE_WEEK.values).to(device)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "# Define a custom collate function to pad tensors in X to the same size\n",
    "def collate_fn(batch):\n",
    "    X, y = zip(*batch)\n",
    "    X_patient = [x[0] for x in X]\n",
    "    X_encounter = [x[1] for x in X]\n",
    "    X_lab_events = [x[2] for x in X]\n",
    "    X_lab_events_padded = pad_sequence(X_lab_events, batch_first=True, padding_value=0)\n",
    "    X_lab_events_padded = [x.unsqueeze(0) for x in X_lab_events_padded]\n",
    "    y = torch.cat(y, dim=0)\n",
    "    return X_patient, X_encounter, X_lab_events_padded, y\n",
    "\n",
    "train_data = PatientEncounter(patients, encounters, lab_events, labels)\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1]),\n",
       " torch.Size([1, 49]),\n",
       " torch.Size([1, 1044, 2]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_x = next(iter(train_dataloader))\n",
    "example_x[0][0].shape, example_x[1][0].shape, example_x[2][0].shape, example_x[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
       "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000], dtype=torch.float64,\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LabModule(nn.Module):\n",
    "    '''\n",
    "    Lab specific module, which takes in a batch of lab events and outputs a batch of lab embeddings.\n",
    "    '''\n",
    "    def __init__(self, num_lab_types):\n",
    "        super().__init__()\n",
    "        self.lab_type = nn.Linear(in_features=1, out_features=5) # 5-dim lab type embedding\n",
    "        self.lab_value = nn.Linear(in_features=1, out_features=5) # 5-dim lab value embedding\n",
    "        self.layer_out = nn.Linear(in_features=10, out_features=5) # 5-dim lab output embedding\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.cat(x, dim=0) # dim = (batch_size, max_seq_len, 2)\n",
    "        x_type = x[:, :, 0].unsqueeze(2)\n",
    "        x_value = x[:, :, 1].unsqueeze(2)\n",
    "        out = torch.cat((self.lab_type(x_type), self.lab_value(x_value)), dim=2)\n",
    "        out = self.layer_out(out) # dim = (batch_size, max_seq_len, 5)\n",
    "        return(out)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1) # dim = (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)) # dim = (d_model/2)\n",
    "        pe = torch.zeros(max_len, 1, d_model) # dim = (max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class PatientEncounterModel(nn.Module):\n",
    "    '''\n",
    "    Patient encounter DL model structure.\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model: int, # embedding dimension\n",
    "        nhead: int, # number of heads in multi-head attention\n",
    "        d_hid: int, # dimension of feedforward network model\n",
    "        nlayers: int, # number of encoder layers\n",
    "        dropout: float, # dropout probability\n",
    "        embed_event_dim: int, # dimension of event embedding\n",
    "        num_static_features: int, # number of static features\n",
    "        num_transformer_layers: 2, # number of transformer layers\n",
    "        num_mlp_layers: int=2, # number of MLP layers\n",
    "        num_mlp_features: int=11, # number of MLP features\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Linear(embed_event_dim, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, embed_event_dim)\n",
    "        self.lab_module = LabModule(num_lab_types=num_lab_types)\n",
    "        self.layer_out = nn.Linear(in_features=num_static_features+d_model, out_features=10)\n",
    "        self.fc1 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.fc2 = nn.Linear(in_features=10, out_features=10)\n",
    "        self.fc3 = nn.Linear(in_features=10, out_features=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.lab_module(x[2]) # only lab-specific module for now\n",
    " \n",
    "        # 4: feed modality-specific outputs into transformer architecture\n",
    "        out = self.encoder(out) * math.sqrt(self.d_model)\n",
    "        out = self.pos_encoder(out)\n",
    "        out = self.transformer_encoder(out)\n",
    "        out = torch.mean(out, dim=1, keepdim=True)\n",
    "\n",
    "        # 5: concatenate outputs from transformer structure with static features\n",
    "        out = torch.stack([out], dim=0).squeeze(0).squeeze(1)\n",
    "        x_patient = torch.stack(x[0], dim=0).squeeze(2)\n",
    "        x_encounter = torch.stack(x[1], dim=0).squeeze(1)\n",
    "        out = torch.cat([x_patient, x_encounter, out], dim=1)\n",
    "\n",
    "        # 6: feed concatenated output into MLP architecture\n",
    "        out = self.layer_out(out)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = self.sigmoid(out)\n",
    "        out = out.squeeze(1)\n",
    "\n",
    "        return(out)\n",
    "\n",
    "model = PatientEncounterModel(\n",
    "    num_static_features=74, # number of static features\n",
    "    num_transformer_layers=2, # number of transformer layers\n",
    "    num_mlp_layers=2, # number of MLP layers\n",
    "    num_mlp_features=11, # number of MLP features\n",
    "    d_model=100, # embedding dimension\n",
    "    nhead=2, # number of heads in multi-head attention\n",
    "    d_hid=5, # dimension of feedforward network model\n",
    "    nlayers=2, # number of encoder layers\n",
    "    dropout=0.1, # dropout probability\n",
    "    embed_event_dim=5 # dimension of event embedding\n",
    ").to(device).double()\n",
    "\n",
    "x = next(iter(train_dataloader))\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.000001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     5] loss: 0.693\n",
      "[1,    10] loss: 0.693\n",
      "[1,    15] loss: 0.693\n",
      "[1,    20] loss: 0.693\n",
      "[1,    25] loss: 0.693\n",
      "[1,    30] loss: 0.693\n",
      "[1,    35] loss: 0.693\n",
      "[1,    40] loss: 0.693\n",
      "[1,    45] loss: 0.693\n",
      "[1,    50] loss: 0.693\n",
      "[1,    55] loss: 0.693\n",
      "[1,    60] loss: 0.693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:113] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [64], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m outputs \u001b[39m=\u001b[39m model([X_patient, X_encounter, X_lab])\n\u001b[1;32m     16\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, y)\n\u001b[0;32m---> 17\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m \u001b[39m# print statistics\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # get the inputs; data is a list of [patient, encounter, lab, y]\n",
    "        X_patient, X_encounter, X_lab, y = data\n",
    "        X_patient = [x.to(device) for x in X_patient]\n",
    "        X_encounter = [x.to(device) for x in X_encounter]\n",
    "        X_lab = [x.to(device) for x in X_lab]\n",
    "        y = y.to(device).double()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model([X_patient, X_encounter, X_lab])\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 5 == 4: # print every 5 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 5))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
